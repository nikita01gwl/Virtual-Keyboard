{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threatened-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#Dleap library to detect the face and then the eyes\n",
    "import dlib\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "#can have different indexes if there are multiple webcams\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#To detect the face\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "#This dat file is basically used to detect points on the face. There are a total of 68 points in our face. The\n",
    "#eyes ranging from 36. See landmarks_points.png for reference\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "#we make this for top to bottom line because we have to draw the line from midpoint of two landmarks. (int)\n",
    "#is used because pixels cant be divided or float.\n",
    "def midpoint(p1,p2):\n",
    "    return (int)((p1.x + p2.x)/2), (int)((p1.y+p2.y)/2)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "def get_blinking_ratio(eye_points, facial_landmarks):\n",
    "    \n",
    "        #36 is the start point of eyes and 39 the end point. We draw a line from left to right and from top \n",
    "        #to bottom. When top to bottom of eyes length becomes 0, means, we are blinking eyes.\n",
    "        \n",
    "        left_point = (facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y)\n",
    "        right_point = (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y)\n",
    "        center_top = midpoint(facial_landmarks.part(eye_points[1]),facial_landmarks.part(eye_points[1]))\n",
    "        center_bottom = midpoint(facial_landmarks.part(eye_points[5]),facial_landmarks.part(eye_points[5]))\n",
    "        \n",
    "        \n",
    "        #for horizontal line\n",
    "        #hor_line = cv2.line(frame, left_point,right_point, (0,255,0), 2 )\n",
    "        \n",
    "        #for vertical line\n",
    "        #ver_line = cv2.line(frame, center_top,center_bottom, (0,255,0), 2 )\n",
    "        \n",
    "        #hypot is used to calculate length of lines\n",
    "        hor_line_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "        ver_line_length = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))\n",
    "        \n",
    "        ratio = hor_line_length/ver_line_length\n",
    "        \n",
    "        return ratio\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    \n",
    "    #To obtain grayscale image. Grayscale images are lighter and that is why, we prefer them\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Array where we have all the faces\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        #x,y = face.left(), face.top()\n",
    "        #x1, y1 = face.right(), face.bottom()\n",
    "        \n",
    "        landmarks = predictor(gray,face)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Blinking detection\n",
    "        left_eye_ratio = get_blinking_ratio([36,37,38,39,40,41],landmarks)\n",
    "        right_eye_ratio = get_blinking_ratio([42,43,44,45,46,47],landmarks)\n",
    "        \n",
    "        blinking_ratio = (left_eye_ratio+ right_eye_ratio)/2\n",
    "        \n",
    "        if blinking_ratio>5.7:\n",
    "            cv2.putText(frame,\"Blinking\",(50,150),font,7,(255,0,0)) \n",
    "    \n",
    "    \n",
    "        #Gaze detection\n",
    "        #we need to specify the type of array which is done using np.int32. Numpy is basically used for working wit\n",
    "        #arrays and mathematical operations.\n",
    "        \n",
    "        left_eye_region = np.array([[landmarks.part(36).x, landmarks.part(36).y],\n",
    "                                   [landmarks.part(37).x, landmarks.part(37).y],\n",
    "                                   [landmarks.part(38).x, landmarks.part(38).y],\n",
    "                                   [landmarks.part(39).x, landmarks.part(39).y],\n",
    "                                   [landmarks.part(40).x, landmarks.part(40).y],\n",
    "                                   [landmarks.part(41).x, landmarks.part(41).y]] , np.int32)\n",
    "        \n",
    "        #We draw a polygon in the left eye region. True is whether polygon is closed or not.\n",
    "        #Using polygon we can take exact region of the eye so that we can focus on only that portion\n",
    "        \n",
    "        #cv2.polylines(frame, [left_eye_region], True ,(0,0,255), 2)\n",
    "        \n",
    "        \n",
    "        #We will create a mask here. A mask is simply a new blackwindow nothing else of the same size as the frame\n",
    "        #The polygon that we created of the eye is placed on this mask\n",
    "        height,width,_ = frame.shape\n",
    "        mask = np.zeros((height,width),np.uint8)\n",
    "        \n",
    "        #only 255 because we want it to be white. Since, it will be placed on the mask which is black\n",
    "        cv2.polylines(mask, [left_eye_region], True ,255, 2)\n",
    "        cv2.fillPoly(mask,[left_eye_region],255)\n",
    "        \n",
    "        #This is done toobtain the eye part on the mask and not the threshold\n",
    "        left_eye = cv2.bitwise_and(gray,gray,mask=mask)\n",
    "        \n",
    "        #We will try to take this polygon eye into different window\n",
    "        #[:0] means that  If you have a 2-dimensional list/matrix/array, this notation will give you all the \n",
    "        #values in column 0 (from all rows).\n",
    "        \n",
    "        min_x = np.min(left_eye_region[:,0])\n",
    "        max_x = np.max(left_eye_region[:,0])\n",
    "        min_y = np.min(left_eye_region[:,1])\n",
    "        max_y = np.max(left_eye_region[:,1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #We will create grayscale image of the eye and try creating a threshold and see if this threshold\n",
    "        #is enough for us to use the eye for motion detection\n",
    "        \n",
    "        #gray_eye = cv2.cvtColor(eye,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        gray_eye = left_eye[min_y:max_y, min_x:max_x]\n",
    "        _, threshold_eye = cv2.threshold(gray_eye, 10, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        \n",
    "        #To resize the window we increase the size, none means we are not specifying any particular size\n",
    "        #fx means current size multiplied by 4 here\n",
    "        #Threshold is used to seperate the iris and pupil from thw white part of the eye\n",
    "        threshold_eye = cv2.resize(threshold_eye,None, fx =5, fy=5)\n",
    "        eye = cv2.resize(gray_eye,None, fx =4, fy=4)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"Left eye\",left_eye)\n",
    "        \n",
    "        \n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-techno",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-sleep",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
